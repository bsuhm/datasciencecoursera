---
title: "HAR Smartphone Data"
author: "Bernhard Suhm"
date: "Wednesday, July 22, 2015"
output: pdf_document
---

The Dataset
-----------
This project reworks a dataset provided by the UCI Center for Machine Learning and Intelligent Systems on human activity recognition using smartphones. The data was obtained from recordings of recordings of 30 subjects performing activities of daily living, such as standing, walking, laying, while carrying a waist-mounted smartphone with embedded inertial sensors.

From the description from the researchers, available at http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones:
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

The Variables
-------------

Per instructions, the 79 variables that represent means or standard deviations are included in the tidy dataset, along with the 13 means on frequencies, as they may be useful for modeling down the road.

The outcome variable has 6 values, corresponding to the six activities that subjects were performing. The tidy data set adopts readable labels as suggested in the activities_labels file that came with the data set. Specifically, the numeric activities were converted to factors in the "Activity" variable as follows: Walking, Walking-Upstairs, Walking-Downstairs, Sitting, Standing, Laying.

The subject designation was preserved as a numeric value, but renamed the variable to "Subject".

The Data Processing Script
--------------------------
The processing script will generate a subdirectory "UCI HAR Dataset" in the current working directory. From that point on the script will work in that subdirectory, and it will contain both the original data (after unzipping the source file), as well as the tidy data set "data_tidy.txt".

We decided to go with the "wide" format of a tidy data set, i.e., each row contains all variables from one measurement.

After reading the test and training files containing the measurements, the script uses the features.txt file to establish a mapping between column (indices) of the measurements and variable names, in order to isolate the variables that represent means and standard deviations (just by matching the words "mean" and "std" in the variable names).

Once we have all the indices of measurements that correspond to means and standard deviations, the subset function can extract those columns from the full test and training data sets, and we are building up new "tidy" data frames called "test" and "train". I decided to keep them separate until the very last step, because I want to perform some predictive modeling with them later, and for that I need them separated into training versus test anyway.

Next the script reads the outcome ("y") variable, the subject and activity labels from the corresponding separate input files, and adds those into the tidy data frames, using mutuate for the activities because that function allows us to map the numeric activity labels into readable ones on the fly.

Once the test and training data is tidy in those separate data frames, the script binds the (rows of) test and training data frames together, before using the aggregate command to aggregate the data by the subject and activity columns, and computing means on the fly. The script also gets rid of duplicate subject and activity columns that were created in that step, and make sure the column names.

As final step, the script writes the file into the working directory, which is (still) "UCI HAR Dataset".




